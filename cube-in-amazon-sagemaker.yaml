---
AWSTemplateFormatVersion: '2010-09-09'

Description: Template to setup Cube-in-Amazon-SageMaker environment for people to do geospatial data analysis or AI/ML training.

Metadata: 
  AWS::CloudFormation::Interface: 
    ParameterGroups: 
      - 
        Label: 
          default: "Notebook Configuration"
        Parameters: 
          - NotebookName
          - NotebookInstanceType
          - VolumeSize
          - CodeRepository
      - 
        Label: 
          default: "Notebook Lifecycle Configuration"
        Parameters: 
          - NotebookLifecycleName
          - NotebookLifecycleOnStart

Parameters:

  NotebookName:
    Type: String
    Default: cube-in-sagemaker-notebook
    Description: Enter the name of the SageMaker notebook instance. 

  VolumeSize:
    Type: Number
    Default: 10
    MinValue: 5
    MaxValue: 16384
    ConstraintDescription: Must be an integer between 5 (GB) and 16384 (16 TB).
    Description: Enter the size of the EBS volume in GB.

  CodeRepository:
    Type: String
    Default: https://github.com/opendatacube/cube-in-a-box-dea.git
    Description: Code respository to use with notebook

  NotebookInstanceType:
    Type: String
    Default: ml.t2.xlarge
    Description: Enter the SageMaker notebook instance type. 

  NotebookLifecycleName:
    Type: String
    Default: opendatacube-lifecycle
    Description: Notebook lifecycle name. 
  
  NotebookLifecycleOnCreate:
    Type: String
    Default: |
      #!/bin/bash

      set -e

      # Install required library
      sudo -u ec2-user -i <<'EOF'

      ODC_DIR=/home/ec2-user/SageMaker/odc-env

      ####################################
      # Configure Conda Kernel environment
      ####################################
      WORKING_DIR=$ODC_DIR/custom-miniconda
      KERNEL_NAME="opendatacube"
      PYTHON="3.6"

      mkdir -p "$WORKING_DIR"

      # Install Miniconda
      wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O "$WORKING_DIR/miniconda.sh"
      bash "$WORKING_DIR/miniconda.sh" -b -u -p "$WORKING_DIR/miniconda"
      rm -rf "$WORKING_DIR/miniconda.sh"
      
      # Create a custom conda environment
      source "$WORKING_DIR/miniconda/bin/activate"
      conda create --yes --name "$KERNEL_NAME" python="$PYTHON"

      # Install packages.
      conda activate "$KERNEL_NAME"
      pip install --upgrade pip
      pip install sat-search boto3 packaging folium scikit-image click
      pip install --quiet ipykernel
      conda install --yes --quiet gdal
      conda install --yes --quiet "poppler<0.62"
      conda install --yes --quiet ruamel.yaml
      pip install datacube

      ####################################
      # Create PostGIS data folder
      ####################################
      POSTGIS_DIR="$ODC_DIR/postgis"

      mkdir -p $POSTGIS_DIR

      POSTGRES_DB=opendatacube
      POSTGRES_PASSWORD=opendatacubepassword
      POSTGRES_USER=opendatacube
      PORT=5432
      POSTGIS_IMAGE=kartoza/postgis:11.0-2.5
      docker run -d --name postgis \
      --env POSTGRES_DB=$POSTGRES_DB \
      --env POSTGRES_PASSWORD=$POSTGRES_PASSWORD \
      --env POSTGRES_USER=$POSTGRES_USER \
      -p $PORT:5432 \
      -v $POSTGIS_DIR:/var/lib/postgresql \
      --rm \
      $POSTGIS_IMAGE

      # Initialize PostGIS
      # Config datacube DB connection
      wget https://raw.githubusercontent.com/tom5610/cube-in-amazon-sagemaker/master/scripts/datacube.conf
      sudo cp datacube.conf /etc/datacube.conf
      datacube -v system init
      datacube metadata add https://raw.githubusercontent.com/opendatacube/datacube-alchemist/local-dev-env/metadata.eo_plus.yaml
      datacube product add https://raw.githubusercontent.com/GeoscienceAustralia/dea-config/master/products/ga_s2_ard_nbar/ga_s2_ard_nbar_granule.yaml

      # Stop PostGIS
      docker stop $(docker ps -aq)

      conda deactivate 
      source deactivate

      EOF

  NotebookLifecycleOnStart:
    Type: String
    Default: |
      #!/bin/bash

      set -e

      # Install required library
      sudo -u ec2-user -i <<'EOF'
      
      ODC_DIR=/home/ec2-user/SageMaker/odc-env
      POSTGIS_DIR="$ODC_DIR/postgis"
      WORKING_DIR=$ODC_DIR/custom-miniconda
      KERNEL_NAME="opendatacube"
      PYTHON="3.6"

      # Start postgis database
      POSTGRES_DB=opendatacube
      POSTGRES_PASSWORD=opendatacubepassword
      POSTGRES_USER=opendatacube
      PORT=5432
      POSTGIS_IMAGE=kartoza/postgis:11.0-2.5

      docker run -d --name postgis \
      --env POSTGRES_DB=$POSTGRES_DB \
      --env POSTGRES_PASSWORD=$POSTGRES_PASSWORD \
      --env POSTGRES_USER=$POSTGRES_USER \
      -p $PORT:5432 \
      -v $POSTGIS_DIR:/var/lib/postgresql \
      --rm \
      $POSTGIS_IMAGE
    
      # Config datacube DB connection
      wget https://raw.githubusercontent.com/tom5610/cube-in-amazon-sagemaker/master/scripts/datacube.conf
      sudo cp datacube.conf /etc/datacube.conf

      # 
      source "$WORKING_DIR/miniconda/bin/activate"
      conda activate "$KERNEL_NAME"

      # Configure Jupyter Notebook Kernel 
      python -m ipykernel install --user --name "$KERNEL_NAME" --display-name "KERNEL_NAME"

      conda deactivate 
      source deactivate
      
      EOF

      # OVERVIEW
      # This script stops a SageMaker notebook once it's idle for more than 1 hour (default time)
      # You can change the idle time for stop using the environment variable below.
      # If you want the notebook the stop only if no browsers are open, remove the --ignore-connections flag
      #
      # Note that this script will fail if either condition is not met
      #   1. Ensure the Notebook Instance has internet connectivity to fetch the example config
      #   2. Ensure the Notebook Instance execution role permissions to SageMaker:StopNotebookInstance to stop the notebook 
      #       and SageMaker:DescribeNotebookInstance to describe the notebook.
      #

      # PARAMETERS
      IDLE_TIME=3600

      echo "Fetching the autostop script"
      wget https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-notebook-instance-lifecycle-config-samples/master/scripts/auto-stop-idle/autostop.py

      echo "Starting the SageMaker autostop script in cron"

      (crontab -l 2>/dev/null; echo "5 * * * * /usr/bin/python $PWD/autostop.py --time $IDLE_TIME --ignore-connections") | crontab -
    Description: Notebook lifecycle name. 

Resources:
  # SageMaker Execution Role
  SageMakerIamRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: Allow
            Principal:
              Service: sagemaker.amazonaws.com
            Action: sts:AssumeRole
      Path: "/"
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/AmazonSageMakerFullAccess"
        - "arn:aws:iam::aws:policy/AmazonS3FullAccess"
        - "arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess"

  # SageMaker lifecycle
  NotebookLifecycle:
    Type: "AWS::SageMaker::NotebookInstanceLifecycleConfig"
    Properties: 
      NotebookInstanceLifecycleConfigName: !Ref NotebookLifecycleName
      OnCreate:
        - Content:
            Fn::Base64: !Ref NotebookLifecycleOnCreate
      OnStart: 
        - Content:
            Fn::Base64: !Ref NotebookLifecycleOnStart

  # SageMaker notebook
  NotebookInstance:
    Type: "AWS::SageMaker::NotebookInstance"
    Properties:
      InstanceType: !Ref NotebookInstanceType
      NotebookInstanceName: !Ref NotebookName
      RoleArn: !GetAtt SageMakerIamRole.Arn
      VolumeSizeInGB: !Ref VolumeSize
      DefaultCodeRepository: !Ref CodeRepository
      LifecycleConfigName: !GetAtt NotebookLifecycle.NotebookInstanceLifecycleConfigName
 